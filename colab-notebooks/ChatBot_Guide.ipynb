{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7W3ypnW0WzXasxB0Uj7sN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniasbr/chatbot-vestibulando/blob/main/colab-notebooks/ChatBot_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hfSCpK3ryH9m"
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain-community langchain-openai langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import bs4\n",
        "\n",
        "from langchain import hub\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.messages import AIMessage"
      ],
      "metadata": {
        "id": "53ILgUaL0g3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting API Key and LLM\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OpenAIKey')\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "veJ1yKuf0oXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating chat history function\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "#Creating a model runner that invokes the session history\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
      ],
      "metadata": {
        "id": "yVXXZ7Sd9nD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting config variable with the relevant session id\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}"
      ],
      "metadata": {
        "id": "Rih1m1o196sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling model with message history\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qrUgvbg8-FrT",
        "outputId": "ccbd9ac8-515b-42c1-909b-30dade3e0a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the message history function\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rJ5b1QQp-kXI",
        "outputId": "b3d115a1-1b2d-47ad-97ab-89daf4ef1a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob. How can I assist you today, Bob?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing to a session that has no history, and testing if the context changes.\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qLVL8w7U-rQi",
        "outputId": "66af4ede-8a8e-452d-a11e-4d020dc7825c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I do not have access to that information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing back to see if previous context is still present\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PWxKhSMe-yjq",
        "outputId": "e673b335-b360-4240-b3ba-bea6cc67abc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Bob. How can I assist you today, Bob?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#New imports\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "BADXp-ku_QRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating prompt template, and creating a new model that: takes the input messages, appends it to the entire prompt (that starts with the message defined here)\n",
        "#and pipes the whole thing into the model itself, provoking a response that has the necessary context.\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\",),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "MCMZ8vX8BRJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple call to the model with the prompt context\n",
        "\n",
        "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]})\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cMWUVjejCaQr",
        "outputId": "b5928763-bb69-4311-cd84-a9ed0413fa0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Redefining the history runner, with the chain model instead\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
      ],
      "metadata": {
        "id": "R9ERLudpCqq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc5\"}}"
      ],
      "metadata": {
        "id": "uqmG7V73CwJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the new runner\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Jim\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CMyKGjtnC1Tc",
        "outputId": "47338633-8732-4c51-b639-a6ec228359cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello, Jim! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing if history context is present\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EK2igjzjDE5x",
        "outputId": "327ed346-17a4-498c-a609-62eea41913f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Jim.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a prompt that has a variable in it. Invoking the model now requires a dictionary, with the \"messages\" key\n",
        "#marking where the message inputs should go, and the \"language\" key being used to define the prompt with language specified\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "zDr12AeBDSHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#It does respond in the specified language\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Portuguese\"}\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o1mGBx_MDdZy",
        "outputId": "712ddac4-df0e-4504-ac0e-466b3f7dca20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá, Bob! Como posso ajudar você hoje?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Redefining the history runner, now with the necessary \"input_messages_key\" parameter\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")"
      ],
      "metadata": {
        "id": "pn1dnbpRDyf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc11\"}}"
      ],
      "metadata": {
        "id": "aYsFsiTMGIZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#History runner with language key. The input remains a dictionary\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Portuguese\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fHfcI0hSGyLJ",
        "outputId": "a834ad9c-ccdc-4fbb-df23-5c38f51ca46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Olá, Todd! Como posso ajudar você hoje?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing history context with language key\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Portuguese\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fXWIW1F6HSsy",
        "outputId": "ca554694-f66e-41ca-cddc-3b8e44b4c26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Seu nome é Todd. Como posso ajudar você hoje, Todd?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# History Management\n"
      ],
      "metadata": {
        "id": "RroA7JB0Uf8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "IG9CWMnyUAQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to send only last k messages to context window\n",
        "\n",
        "def filter_messages(messages, k=10):\n",
        "    return messages[-k:]"
      ],
      "metadata": {
        "id": "wyiq7EFvUo05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Redefining chain using message filtering\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=lambda x: filter_messages(x[\"messages\"]))\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ],
      "metadata": {
        "id": "zna4tvrrUq5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 example messages, with the first being the name of the user. Once a new message is appended,\n",
        "#the LLM should not know the users name.\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"hi! I'm bob\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]"
      ],
      "metadata": {
        "id": "vQmJDCoGUzDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This should not be known\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5PSrCl_6VcKp",
        "outputId": "7fbcb137-5a03-4c73-9628-9c4d9ac60533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I don't have access to your personal information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This should be known\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my fav ice cream\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YhA2-TmfVjzD",
        "outputId": "f5385e84-143c-4d8f-f8df-d6eb987d46aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You mentioned earlier that you like vanilla ice cream.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing the new chain in the history runner\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
      ],
      "metadata": {
        "id": "VEIIkkq1VyC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, the calls we made get added to the history, alongside with the predefined messages\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UCdXAlUIWDlk",
        "outputId": "49bb5c49-5a4b-490e-ea36-76015381c8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I don't have access to personal information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now that we have two new messages in the history, the ice cream flavour should\n",
        "#not be known\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"whats my favorite ice cream?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xySiZSRLWZY2",
        "outputId": "74f21b9b-539a-4fc5-9f50-5d654a5a92d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I don't have that information.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}