{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbfg8/qLO4PTQx7D9ro2Lw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniasbr/chatbot-vestibulando/blob/main/colab-notebooks/Responsive_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oERXzzNnXQ7y"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet  langchain langchain-community langchain-chroma bs4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "imvM4EmQX1vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import bs4\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "bEiNm3FtXa1D"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Key and LLM selection"
      ],
      "metadata": {
        "id": "7EyIMNspX7an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OpenAIKey')\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "vlXH1Qk2YCZW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function Definitions"
      ],
      "metadata": {
        "id": "fmN4UdEmhuMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the volatile memory storage. We do not intend to save conversations in a file.\n",
        "\n",
        "store = {}"
      ],
      "metadata": {
        "id": "HU_KQA1gh0wW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "KVVzJYKQht2L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_history(history, k=10):\n",
        "    return history[-k:]"
      ],
      "metadata": {
        "id": "K0k7hEURjr4g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "uGwRsB_1hzEq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Base Prompt and Defining Runner"
      ],
      "metadata": {
        "id": "XECs6znVlqwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You're an assistant who speaks in {language}. Respond in 20 words or fewer\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "rrNe8jyBlvcY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = (\n",
        "    RunnablePassthrough.assign(history=lambda x: filter_history(x[\"history\"]))\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ],
      "metadata": {
        "id": "ym-owxITmCL0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable_with_history = RunnableWithMessageHistory(\n",
        "    runnable,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\",\n",
        ")"
      ],
      "metadata": {
        "id": "PlMHYckWmD30"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Test"
      ],
      "metadata": {
        "id": "QCPcPn0OnMtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runnable_with_history.invoke(\n",
        "    {\"language\": \"portuguese\", \"input\": \"hi im vinicius!\"},\n",
        "    config={\"configurable\": {\"session_id\": \"2\"}},\n",
        ")"
      ],
      "metadata": {
        "id": "xbfZpvX5mTnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in runnable_with_history.stream(\n",
        "    {\"language\": \"portuguese\", \"input\": \"Qual é meu nome?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"2\"}},):\n",
        "  print(r.content, end = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58RP2CDAmx21",
        "outputId": "68474907-0f12-4f0c-ee47-9e07b0a83a36"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seu nome é Vinicius. Como posso ajudar você hoje?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Simple ChatBot Loop\n",
        "This is the simplest implementation of the ChatBot. It is nice to see it working!"
      ],
      "metadata": {
        "id": "9gbq5V5IofSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"\"\n",
        "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
        "\n",
        "while user_input != \"Fim.\":\n",
        "  user_input = input(\"Usuário: \")\n",
        "  print(\"ChatBot:\",end=\" \")\n",
        "  for r in runnable_with_history.stream(\n",
        "      {\"language\": \"portuguese\", \"input\": user_input},\n",
        "    config=config,\n",
        "    ):\n",
        "    print(r.content, end=\"\")\n",
        "  print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "626y45HroumK",
        "outputId": "7a47ed45-f3a1-4ead-b79f-52e610473d60"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuário: oi\n",
            "ChatBot: Olá! Como posso ajudar você hoje?\n",
            "Usuário: eu quero aprender ingles\n",
            "ChatBot: Posso te ajudar com isso! Vamos praticar juntos? Estou aqui para responder suas perguntas.\n",
            "Usuário: como se diz brigadeiro em ingles\n",
            "ChatBot: Brigadeiro em inglês é \"brigadeiro\".\n",
            "Usuário: como que monta um cubo m[agico\n",
            "ChatBot: Para montar um cubo mágico, siga tutoriais online ou use métodos de resolução passo a passo. Boa sorte!\n",
            "Usuário: eu gosto de voce\n",
            "ChatBot: Fico feliz em saber! Estou aqui para ajudar no que precisar. Obrigado pelo carinho.\n",
            "Usuário: o que eu te perguntei em ingles mesmo?\n",
            "ChatBot: Você perguntou \"como se diz brigadeiro em inglês?\"\n",
            "Usuário: Fim.\n",
            "ChatBot: Se precisar de mais alguma coisa, estou à disposição. Até mais!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Document Parsing"
      ],
      "metadata": {
        "id": "W1C-TXLlzamE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading already parsed data, extracted from https://www.pg.unicamp.br/norma/31594/0\n",
        "\n",
        "loader = TextLoader(\"clean_data.txt\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "Xk92ijPezgBu"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCMRFxvaWKMF",
        "outputId": "0b20471a-26bb-4e91-fd26-752dff81ab20"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in all_splits:\n",
        "  i.metadata['source'] = 'https://www.pg.unicamp.br/norma/31594/0'"
      ],
      "metadata": {
        "id": "3DWvJ-GdZoa0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ],
      "metadata": {
        "id": "9jNV0MSmaMdw"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
      ],
      "metadata": {
        "id": "ylKf6gm7amVE"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs = retriever.invoke(\"Quantas vagas de ampla concorrência tem o curso de Ciência de Computação na Unicamp?\")"
      ],
      "metadata": {
        "id": "mmvdwgU3aurC"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(retrieved_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B-RGKCla7Vq",
        "outputId": "23bcb9f7-1cd0-4056-a829-36d3733f0f74"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(retrieved_docs[2].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7-8s3l_a_kq",
        "outputId": "9321aa3a-b657-4096-b012-17bd9aeb2a84"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cursos: Engenharia de Computação (Integral), Total Vagas Regulares: 90, Total Vagas VU: 63, Ampla Concorrência (Mínimo): 39, Ampla Concorrência (Máximo): 49, Reserva de Vagas para PP (15%*): 14, Reserva de Vagas para PP (27,2%*): 24\n",
            "Cursos: Engenharia de Controle e Automação (Noturno), Total Vagas Regulares: 50, Total Vagas VU: 33, Ampla Concorrência (Mínimo): 19, Ampla Concorrência (Máximo): 25, Reserva de Vagas para PP (15%*): 8, Reserva de Vagas para PP (27,2%*): 14\n",
            "Cursos: Engenharia de Manufatura (Integral), Total Vagas Regulares: 60, Total Vagas VU: 45, Ampla Concorrência (Mínimo): 29, Ampla Concorrência (Máximo): 36, Reserva de Vagas para PP (15%*): 9, Reserva de Vagas para PP (27,2%*): 16\n",
            "Cursos: Engenharia de Produção (Integral), Total Vagas Regulares: 60, Total Vagas VU: 45, Ampla Concorrência (Mínimo): 29, Ampla Concorrência (Máximo): 36, Reserva de Vagas para PP (15%*): 9, Reserva de Vagas para PP (27,2%*): 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You're an assistant for question-answering tasks who speaks in portuguese. Use the following pieces of retrieved context to answer questions about vestibular da Unicamp.If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n {context}\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Yg0ZeLoQbqvz"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"input\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "n04_-gtdiI90"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Quais são as matérias que pesam mais em engenharia de computação?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YcjZPLM0m-ZH",
        "outputId": "c42a6ce2-d355-4ad2-fc1e-02d6a5e28cd6"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As matérias que mais pesam em Engenharia de Computação na Unicamp são MAT, LPL e FIS, com pesos 3, 2 e 1, respectivamente.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
        "which might reference context in the chat history, formulate a standalone question \\\n",
        "which can be understood without the chat history. Do NOT answer the question, \\\n",
        "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "-YezkMVrp7vc"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    model, retriever, contextualize_q_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "BTm2HkHTrXFy"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_system_prompt = \"\"\"You're an assistant for question-answering tasks who speaks in portuguese. Use the following pieces of retrieved context to answer questions about vestibular da Unicamp.If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n {context}\"\"\""
      ],
      "metadata": {
        "id": "1TpzHK7FrkY5"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", qa_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fdsgmNcXrwWG"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(model, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "QKFS5QTwr0XZ"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    (RunnablePassthrough.assign(chat_history=lambda x: filter_history(x[\"chat_history\"])) | rag_chain),\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "i1zSeWc1sHoz"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"\"\n",
        "config = {\"configurable\": {\"session_id\": \"abc5\"}}\n",
        "\n",
        "while user_input != \"Fim.\":\n",
        "  user_input = input(\"Usuário: \")\n",
        "  print(\"ChatBot:\",end=\" \")\n",
        "  for r in conversational_rag_chain.stream(\n",
        "      {\"input\": user_input},\n",
        "    config=config,\n",
        "    ):\n",
        "    if('answer' in r.keys()):\n",
        "      print(r['answer'], end=\"\")\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "RJT3M4DisTxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}